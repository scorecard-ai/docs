---
title: "Playground"
description: "The Playground is where you test and refine your AI agent prompts using real data. It's a three-panel interface that lets you select test data, edit prompts with Jinja templating, configure AI models, and see results in real-time."
---

import { DarkLightImage } from "/snippets/dark-light-image.jsx";

<DarkLightImage
  lightSrc="/images/playground-light.png"
  darkSrc="/images/playground-dark.png"
  caption="Playground overview showing the three-panel interface."
  alt="Screenshot of the Playground showing testset selection, prompt editing, and preview panels."
/>

## Getting Started

### 1. Select Your Test Data (Left Panel)

**Choose a Testset:**
- Click the "Choose Testset" dropdown at the top left
- Select a testset that contains the data you want to test your prompt against
- If no testsets exist, create one from the [Testsets](/features/testsets) page first
- Once selected, testcases from the testset will appear in the left panel

**Select Testcases:**
- Click on individual testcases to select them
- Hold Shift and click to select multiple testcases
- Selected testcases have a highlighted left border
- Hover over the info icon to see the full testcase data

### 2. Edit Your Prompt (Middle Panel)

**Choose a Prompt:**
- Select a prompt from the "Prompt" dropdown at the top of the middle panel
- If no prompts exist, create one from the [Prompts](/features/prompts) page first

**Work with Prompt Versions:**
- The "Prompt Versions" section shows all versions of your selected prompt
- Click any version to switch to it
- The status indicator shows "All changes saved" when there are no pending changes
- The production version is marked with a "Production" badge

**Edit Prompt Templates:**
- Use the "Prompt Templates" tab to write your prompts
- The editor supports [Jinja syntax](https://jinja.palletsprojects.com/) for dynamic content
- Insert variables from your testcase data like `{{variable_name}}` or use `{{allInputs}}` for all inputs
- Add multiple messages by clicking "+ ADD MESSAGE"
- Set message roles (System, User, Assistant) using the role dropdown
- Remove messages with the trash icon

**Configure Model Settings:**
- Switch to the "Model Settings" tab
- Choose your AI model (GPT-4, Claude, etc.)
- Adjust parameters like temperature, max tokens, and top-p
- These settings affect how the AI generates responses

### 3. Preview and Test (Right Panel)

**Template Preview:**
- The "Template Preview" tab shows how your prompt looks with real data
- Variables are automatically replaced with values from selected testcases
- This helps you verify your Jinja templating is working correctly

**Run Tests:**
- Click "Try" to test your prompt on selected testcases
- Click "Kickoff Run" to create a full run for the entire testset, which will appear in your run history
- Results appear in the "Results" tab automatically

**View Results:**
- The "Results" tab shows AI responses for each testcase
- See response time, token count, and full output
- Click the completion badge to open a detailed results modal
- Green indicates successful completion, yellow shows partial results

## Key Features

### Jinja Templating
Your prompts support Jinja syntax for dynamic content:
```jinja
Hello {{name}}, your order #{{order_id}} is {{status}}.
```

### Multi-testcase Testing
- Test individual testcases for quick iteration
- Run all testcases for comprehensive evaluation
- Kickoff full runs that are tracked in your run history
- Compare results across different prompt versions

### Version Management
- Save new versions of your prompts with the "SAVE" button in the header
- Switch between versions in the "Prompt Versions" panel to compare performance
- Mark versions as production when ready to deploy

### Real-time Preview
- See exactly how your prompt will look with real data
- Catch templating errors before running tests
- Understand how variables are populated

## Best Practices

1. **Start Small**: Select one testcase first to quickly iterate on your prompt
2. **Use Variables**: Leverage Jinja templating to make prompts dynamic and reusable
3. **Test Thoroughly**: Run all testcases before publishing to production
4. **Save Versions**: Create new versions when making significant changes
5. **Monitor Results**: Check response times and token usage to optimize costs

## Common Workflows

**Quick Testing:**

Select a testcase → Edit prompt → Preview → Try → Review results

**Comprehensive Evaluation:**

Select all testcases → Edit prompt → Try All → Analyze results modal

**Version Comparison:**

Test Version A → Switch to Version B → Test → Compare results

**Full Run Creation:**

Select testset → Edit prompt → Kickoff Run → Monitor in run history

The Playground makes prompt engineering intuitive by providing immediate feedback and real data testing in a single interface.