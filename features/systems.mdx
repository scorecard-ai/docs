---
title: "Systems: Beyond Prompts"
description: "Evaluate a simple LLM system with Scorecard in minutes."
---

import { DarkLightImage } from "/snippets/dark-light-image.jsx";

## Systems at a glance

A System brings together everything that shapes your AI’s behavior: prompts, model settings, and configuration. Instead of tweaking prompts in isolation, you version the full setup and test it as one unit.

<DarkLightImage lightSrc="/images/systems/systems-overview-light.png" darkSrc="/images/systems/systems-overview-dark.png" caption="Systems list with latest configuration." alt="Screenshot of the Systems list in the UI." />

## Why use Systems?

- **One place for configuration**: Keep prompts, parameters, and options together
- **Versioned changes**: Create versions as you iterate and compare results
- **Production clarity**: See which version is latest vs. production

## Create a System

Click New System, give it a name and description, and paste configuration JSON for your app (whatever drives your model behavior, e.g., style, temperature, or other flags). Scorecard versions this for you.

<DarkLightImage lightSrc="/images/systems/systems-new-light.png" darkSrc="/images/systems/systems-new-dark.png" caption="Create System modal." alt="Screenshot of creating a new System in the UI." />

## Inspect a System

Open a System to view details, timestamps, and all versions. You can quickly scan configurations and see which version is latest or marked as production.

<DarkLightImage lightSrc="/images/systems/systems-detail-light.png" darkSrc="/images/systems/systems-detail-dark.png" caption="System details with version history and configs." alt="Screenshot of System details and versions in the UI." />

## Test the full setup

Systems work hand-in-hand with Testsets, Metrics, and Runs so you evaluate realistic changes—not just prompt text. Try it with our quickstart and see how different configurations impact results.

## Why it matters

- Ship changes with confidence by comparing full-system versions, not one-off prompts.
- Reduce prompt drift by keeping parameters and context under version control.
- Create a clear audit trail of what’s in production and why.
- Improve evaluation quality by testing the exact configuration users will experience.

## If you call it something else

- **Prompt pipeline / agent configuration / workflow config**: Systems capture the whole thing.
- **Where versions live**: Each System has multiple versions; you can label one as production and compare to latest.
- **What’s captured**: Prompts, model ids/params, tools or routing settings, and custom flags that change outputs.

## Use cases

- A/B prompts or model choices across the same testset.
- Tune temperature, system messages, or tool settings and measure impact.
- Promote the best-performing version to production, with rollback safety.
- Track regressions across releases by re-running previous versions.

_[→ Try the Joke Bot Quickstart](https://github.com/scorecard-ai/scorecard-examples/tree/main/nodejs-jokebot)_
