---
title: "Quickstart"
description: "Evaluate a simple LLM system with Scorecard in minutes."
mode: "center"
---

Scorecard has [Python](https://pypi.org/project/scorecard-ai) and [JavaScript](https://www.npmjs.com/package/scorecard-ai) SDKs. If you're using Python, you can follow along in [Google Colab](https://colab.research.google.com/drive/1A53j48o75Decrjz7WzDVP62XeDEKCHHP).

## Steps

<Steps>
  <Step title="Setup accounts">
    Create a [Scorecard account](https://app.scorecard.io/dashboard) and an [OpenAI account](https://platform.openai.com), then set your [Scorecard API key](https://app.scorecard.io/settings) and [OpenAI API key](https://platform.openai.com/api-keys) as environment variables.

    ```sh
    export SCORECARD_API_KEY="your_scorecard_api_key"
    export OPENAI_API_KEY="your_openai_api_key"
    ```
  </Step>

  <Step title="Install SDKs">
    Install the Scorecard and OpenAI libraries:

    <CodeGroup>
      ```sh Python (pip)
      pip install --pre scorecard-ai
      pip install openai
      ```

      ```sh JavaScript (npm)
      npm install scorecard-ai@alpha
      npm install openai
      ```
    </CodeGroup>
  </Step>

  <Step title="Create simple LLM system">
    Create a simple LLM system to evaluate. When using Scorecard, systems use dictionaries as input and output.
    
    For the quickstart, the LLM system is `run_system()`, which translates the user's message to a different tone.
    
    `input["original"]` is the user's message and `input["tone"]` is the tone to translate to. The output is a dictionary containing the translated message (`rewritten`).

    <CodeGroup>
      ```py Python
      from openai import OpenAI
      
      # By default, the API key is taken from the environment variable.
      openai = OpenAI()
      
      # Example:
      # run_system({"original": "Hello, world!", "tone": "formal"})
      # -> {"rewritten": "Greetings, world."}
      def run_system(system_input: dict) -> dict:
          response = openai.responses.create(
              model="gpt-4o-mini",
              instructions=f"You are a tone translator. Convert the user's message to the tone: {system_input['tone']}",
              input=system_input['original'],
          )
          return {
              "rewritten": response.output_text
          }
      ```

      ```js JavaScript
      import OpenAI from 'openai';

      // By default, the API key is taken from the environment variable.
      const openai = new OpenAI();
      
      // Example:
      // runSystem({"original": "Hello, world!", "tone": "formal"})
      // -> {"rewritten": "Greetings, world."}
      async function runSystem(systemInput) {
        const response = await openai.responses.create({
          model: 'gpt-4o-mini',
          instructions: `You are a tone translator. Convert the user's message to the tone: ${systemInput.tone}`,
          input: systemInput.original,
        });
        return {
          rewritten: response.output_text
        };
      }
      ```
    </CodeGroup>
  </Step>

  <Step title="Setup Scorecard">
    <CodeGroup>
      ```py Python
      from scorecard_ai import Scorecard

      # By default, the API key is taken from the environment variable.
      scorecard = Scorecard()
      ```

      ```js JavaScript
      import Scorecard from 'scorecard-ai';

      // By default, the API key is taken from the environment variable.
      const scorecard = new Scorecard();
      ```
    </CodeGroup>
  </Step>
  
  <Step title="Create Project">
    Create a Project in Scorecard. This will be where your tests and runs will be stored. Copy the Project ID for later.

    <CodeGroup>
      ```py Python
      PROJECT_ID = "310"  # Replace with your project ID
      ```

      ```js JavaScript
      const PROJECT_ID = "310"; // Replace with your Project ID
      ```
    </CodeGroup>
  </Step>
  
  <Step title="Create Testset with Testcases">
    Create some testcases to represent the inputs to your system and the ideal (`expected`) outputs.

    <CodeGroup>
      ```py Python
      testcases = [
          {
              # `inputs` gets passed to the system.
              "inputs": {
                  "original": "We need your feedback on the new designs ASAP.",
                  "tone": "polite",
              },
              # `expected` is the ideal output of the system used by the LLM-as-a-judge to evaluate the system.
              "expected": {
                  "idealRewritten": "Hi, your feedback is crucial to the success of the new designs. Please share your thoughts as soon as possible.",
              },
          },
          {
              "inputs": {
                  "original": "I'll be late to the office because my cat is sleeping on my keyboard.",
                  "tone": "funny",
              },
              "expected": {
                  "idealRewritten": "Hey team! My cat's napping on my keyboard and I'm just waiting for her to give me permission to leave. I'll be a bit late!",
              },
          },
      ]
      ```

      ```js JavaScript
      const testcases = [
        {
          // `inputs` gets passed to the system.
          inputs: {
            original: 'We need your feedback on the new designs ASAP.',
            tone: 'polite',
          },
          // `expected` is the ideal output of the system used by the LLM-as-a-judge to evaluate the system.
          expected: {
            idealRewritten: 'Hi! your feedback is crucial to the success of the new designs. Please share your thoughts as soon as possible.',
          },
        },
        {
          inputs: {
            original: "I'll be late to the office because my cat is sleeping on my keyboard.",
            tone: 'funny',
          },
          expected: {
            idealRewritten: "Hey team! My cat's napping on my keyboard and I'm just waiting for her to give me permission to leave. I'll be a bit late!",
          },
        },
      ];
      ```
    </CodeGroup>
  </Step>
  
  <Step title="Create Metrics">
    From the Scorecard UI, create an AI-graded Metric named "Tone accuracy" to evaluate the tone translator system on. Copy the Metric ID for later.

    <Frame caption="Creating a Metric in the Scorecard UI." height="500">
      <img className="block dark:hidden" height="100" src="/images/quickstart/create-metric-light.png" alt="Screenshot of creating a 'Tone accuracy' metric." />
      <img className="hidden dark:block" height="100" src="/images/quickstart/create-metric-dark.png" alt="Screenshot of creating a 'Tone accuracy' metric." />
    </Frame>

    <CodeGroup>
      ```py Python
      METRIC_IDS = ["987"]  # Replace with your Metric ID
      ```

      ```js JavaScript
      const METRIC_IDS = ["987"]; // Replace with your Metric ID
      ```
    </CodeGroup>
  </Step>

  <Step title="Evaluate system">
    Run the system against the Metrics you've created and record the results in Scorecard.

    <CodeGroup>
      ```py Python
      from scorecard_ai.lib import run_and_evaluate

      run = run_and_evaluate(
          client=scorecard,
          project_id=PROJECT_ID,
          metric_ids=METRIC_IDS,
          system=lambda input: run_system(input),
          testcases=testcases,
      )

      print(f'Go to {run["url"]} and view your results.')
      ```

      ```js JavaScript
      import { runAndEvaluate } from 'scorecard-ai';
      
      const run = await runAndEvaluate(scorecard, {
        projectId: PROJECT_ID,
        metricIds: METRIC_IDS,
        system: runSystem,
        testcases: testcases,
      });
      console.log(`Go to ${run.url} and view your results.`);
      ```
    </CodeGroup>
  </Step>

  <Step title="Analyze results">
    Finally, review the results in Scorecard to understand the performance of the tone translator system.

    <Frame caption="Viewing results in the Scorecard UI." height="500">
      <img className="block dark:hidden" height="100" src="/images/quickstart/scoring-done-light.png" alt="Screenshot of viewing results in the Scorecard UI." />
      <img className="hidden dark:block" height="100" src="/images/quickstart/scoring-done-dark.png" alt="Screenshot of viewing results in the Scorecard UI." />
    </Frame>
  </Step>
</Steps>