---
title: "What Is Scorecard?"
description: "The complete platform for building, testing, and deploying production-ready LLM applications"
icon: "rocket"
---

<Frame>
![Scorecard Workflow](/images/what-is-scorecard/1.gif)
</Frame>

## Welcome to Scorecard

Scorecard is designed to help teams **ship LLM applications faster** with confidence in their quality. We provide the complete toolkit for testing, evaluating, and monitoring AI applications throughout their lifecycle.

<CardGroup cols={3}>
  <Card title="Quick Start" icon="play" href="/intro/quickstart">
    Get up and running in 5 minutes
  </Card>
  <Card title="Watch Demo" icon="video" href="https://scorecard.io/demo">
    See Scorecard in action
  </Card>
  <Card title="Join Community" icon="users" href="https://scorecard.io/slack">
    Connect with other teams
  </Card>
</CardGroup>

## Why teams choose Scorecard

<Tabs>
  <Tab title="For Engineers">
    ### Ship with confidence
    - **Automated testing** catches regressions before production
    - **Version control** for prompts and configurations
    - **CI/CD integration** fits your existing workflow
    - **SDK support** for Python, TypeScript, and more
    
    ```python
    # Test in one line - runs testset and evaluates results
    scorecard.run("my-testset", model="gpt-4")
    ```
  </Tab>
  <Tab title="For Product Teams">
    ### Move faster, break less
    - **No-code testing** through our playground
    - **Visual analytics** to understand performance
    - **Collaborative workflows** for cross-functional teams
    - **Real-time monitoring** of production quality
  </Tab>
  <Tab title="For Leaders">
    ### Scale AI reliably
    - **Reduce AI incidents** by up to 90%
    - **Ship 3x faster** with automated workflows
    - **Save engineering time** on manual testing
    - **Ensure compliance** with audit trails
  </Tab>
</Tabs>

## From manual testing to automation

Most teams start their LLM journey with manual "vibe checks" - but this doesn't scale.

<Frame caption="The evolution of LLM testing maturity">
![Stages in the Evaluation Journey](/images/llm-developer-journey/4.png)
</Frame>

<AccordionGroup>
  <Accordion title="Stage 1: Manual Testing" icon="hand" defaultOpen>
    Teams test by manually trying prompts and checking outputs. Works for demos, breaks in production.
    
    **Problems:** No consistency, catches few edge cases, wastes developer time
  </Accordion>
  <Accordion title="Stage 2: Spreadsheet Tracking" icon="table">
    Teams track test cases in spreadsheets. Better than nothing, still manual.
    
    **Problems:** Manual copy-paste, subjective evaluation, version control issues
  </Accordion>
  <Accordion title="Stage 3: Automated Evaluation" icon="robot">
    Scorecard automates the entire testing workflow with consistent, scalable evaluation.
    
    **Benefits:** Catch regressions instantly, test at scale, objective metrics
  </Accordion>
</AccordionGroup>

## How Scorecard works

<Steps>
  <Step title="Create your testset" icon="1">
    Start with 5-10 test cases that represent your use case. Import from CSV, create in UI, or generate from production logs.
    
    ```python
    # Create a testset with test cases
    testset = scorecard.create_testset(
        name="customer-support",
        cases=[{"input": "How do I reset my password?"}]
    )
    ```
  </Step>
  <Step title="Run your tests" icon="2">
    Execute against your LLM application through our playground, SDK, or CI/CD pipeline.
    
    ```python
    # Execute testset against your LLM with specified config
    run = scorecard.run(
        testset_id="customer-support",
        model_config={"temperature": 0.7}
    )
    ```
  </Step>
  <Step title="Evaluate results" icon="3">
    Score outputs with pre-built metrics, custom evaluators, or human review.
    
    ```python
    # Evaluate outputs using predefined metrics
    results = run.evaluate(
        metrics=["helpfulness", "accuracy", "tone"]
    )
    ```
  </Step>
</Steps>

### Testing at every scale

<Tabs>
  <Tab title="Sample (5-10 tests)">
    Perfect for quick iteration and demos. Test your most important cases.
  </Tab>
  <Tab title="Golden (100 tests)">
    Production-ready coverage of core functionality. Catch regressions before deploy.
  </Tab>
  <Tab title="Comprehensive (1000+ tests)">
    Full coverage including edge cases. Monitor performance across all scenarios.
  </Tab>
</Tabs>

## See Scorecard in action

<CardGroup cols={2}>
  <Card title="DoorDash" icon="truck">
    "Scorecard helped us reduce hallucinations by 73% in our support bot while shipping 3x faster."
    
    **Results:** 90% fewer customer complaints, 50% reduction in testing time
  </Card>
  <Card title="Notion" icon="file">
    "We use Scorecard to ensure Notion AI delivers consistent, high-quality responses across millions of users."
    
    **Results:** 95% quality consistency, automated regression testing
  </Card>
</CardGroup>

<Tip>
**Pro tip:** Most teams see ROI within the first week by catching issues that would have reached production.
</Tip>

## Start building better LLM apps today

<CardGroup cols={2}>
  <Card title="Start with Playground" icon="play" href="/features/playground">
    No code required. Test your prompts and see results instantly.
  </Card>
  <Card title="Setup Integration" icon="code" href="/how-to-use-scorecard/trigger-run-with-github-actions">
    Add testing to your codebase in minutes.
    
    ```bash
    pip install scorecard-ai
    ```
  </Card>
</CardGroup>

### Resources to get started

<CardGroup cols={3}>
  <Card title="5-Minute Quickstart" icon="timer" href="/intro/quickstart">
    Your first test in 5 minutes
  </Card>
  <Card title="Testset Management" icon="folder" href="/features/testset-management">
    Create and manage test cases
  </Card>
  <Card title="RAG Guide" icon="star" href="/how-to-use-scorecard/rag-retrieval-augmented-generation">
    Advanced evaluation techniques
  </Card>
</CardGroup>

### Learn more

- **Technical details:** [Technical System Overview](/intro/technical-system-overview) for engineers
- **Integration guides:** Connect with [GitHub Actions](/how-to-use-scorecard/trigger-run-with-github-actions) and automation workflows
- **Community:** Join our [Slack](https://scorecard.io/slack) to connect with other teams

<Info>
**Questions?** Our team is here to help at support@scorecard.ai or via the chat widget.
</Info>